\pagenumbering{gobble}

%\begin{titlepage}
\null\vspace{\fill}
\begin{center}
\Huge{\textbf{Composing Dynamic Soundscapes Using Neural Networks and Sentimental Input}}\\
\vspace*{2\baselineskip}
\Large{\textbf{CS350 Dissertation Project Final Report}}\\
University of Warwick, BSc Data Science\\
\vspace*{2\baselineskip}
\Large{\textbf{Author}}\\
Harrison Wilde (u1600779)\\
\vspace*{2\baselineskip}
\Large{\textbf{Supervisor}}\\
Professor Graham Cormode\\
\vspace*{3\baselineskip}
\end{center}
% \end{titlepage}
\vspace{\fill}

\onehalfspacing

\hypersetup{linkcolor = black}
\newpage
\pagenumbering{roman}
\tableofcontents
\newpage
\newpage
\setcounter{page}{3}
% list of figures have to be added manually to table of contents
\listoffigures 
\newpage

\listoftables
\newpage
\hypersetup{linkcolor = red}

% \null\vspace{\fill}
% \renewcommand{\abstractname}{Acknowledgements}
% \begin{abstract}
% \phantomsection  % required if using hyperref
% \addcontentsline{toc}{section}{\abstractname}
% \setlength\parindent{0pt}
% \setlength{\parskip}{6pt plus 2pt minus 1pt}
% \normalsize
% \noindent
% My personal tutor Professor Bärbel Finkenstädt and trusted advisor and friend Dr Matthew Leeke alongside my supervisor Professor Graham Cormode have shown consistent support on a personal, professional and academic level throughout my time at the University; for this I owe them great thanks.

% The support of my family and friends has been invaluable throughout this process; especially my mother Katie who has always been unwavering in her support of me in the pursuit of my aspirations.

% I would also like to thank all of the artists and musicians who gave feedback on my work or were featured in the training corpus; without their tireless work the world would be severely lacking in value and beauty. Most notably, the works of \href{https://www.youtube.com/watch?v=JKsVsEXZXe8}{Ryuichi Sakamoto}, \href{https://music-from-memory.bandcamp.com/track/call-me-2}{Gigi Masin}, \href{https://youtu.be/vveVs8axQRc}{Jónsi and Alex Somers}, \href{https://helloflora.bandcamp.com/track/cecilia-lake}{Jamison Isaak} and \href{https://bvdub.bandcamp.com/track/ember-1}{Brock Van Wey} have shaped my years as an undergraduate and offered a great deal of creative and intellectual stimulation as well as instilling a great appreciation for the world and its inhabitants.
% \end{abstract}
% \vspace{\fill}
% \newpage

\null\vspace{\fill}
\renewcommand{\abstractname}{Abstract}
\begin{abstract}
\phantomsection  % required if using hyperref
\addcontentsline{toc}{section}{\abstractname}
\setlength\parindent{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\normalsize
\noindent
This dissertation focusses on the use of deep sequential learning techniques to imitate the very human artistic process of musical composition. Numerous techniques and approaches were applied mainly surrounding developments in Recurrent Neural Networks from the past two decades. The project highlights significant progress made by this research and similar papers as well as the work there is still to be done.

(Is talking about RNNs etc. in the abstract too technical, some of the writing sessions seem to think so but I would disagree given it is a key aspect of the project)

The devised model and architecture effectively captures musical structure and harmony in order to compose pieces which subscribe to the general style of the data used to train the model. Moreover, the chosen training data may have its sentiment analysed and attached as a feature during training to allow for retroactive tuning of the model through passing mood parameter values at the time of generation which then influence the mood of the outputs.

The model is versatile and performant, to the point of it being potentially on par with the current cutting edge attempts at making progress in this field; it utilises recent developments to combat some of the issues in previous attempts whilst improving on the training time required to reach equivalent results.

Testing indicates that the compositional engine can be trained with any genre of music and replicate it reasonably well. Future work would focus on improving the sentiment analysis part and improving integration with the model to perhaps focus on certain key defined features of the music.
\end{abstract}
\vspace{\fill}
\newpage

\pagenumbering{arabic}